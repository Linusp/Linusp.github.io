---
title: Learning to Compose Neural Networks for Question Answering
author: Linusp
layout: page
permalink: /notes/learning_to_compose_nn.html
---
<div id="table-of-contents">
<h2>&#30446;&#24405;</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline1">Notes for page 1</a></li>
<li><a href="#orgheadline2">Notes for page 2</a></li>
<li><a href="#orgheadline3">Notes for page 3</a></li>
<li><a href="#orgheadline4">Notes for page 4</a></li>
<li><a href="#orgheadline5">Notes for page 5</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline1" class="outline-2">
<h2 id="orgheadline1">Notes for page 1</h2>
<div class="outline-text-2" id="text-orgheadline1">
<p>
问题是这样的: 给定一个 "world representation" 比如说图片或一段文章，然后再给一个问题，要根据问题从 "world representation" 中得到答案
</p>

<p>
The model translates from questions to dynamically assembled neural networks, then applies these networks to world representations(images or knowledge bases) to produce answers.
</p>

<p>
上面这个是总体的思想: 直接从问题中得到一个动态组装起来的神经网络，然后用这个网络从 "world representation" 中得到答案，也就是说，用 'world representation' 作为输入。
</p>

<p>
We take advantage of two largely independent lines of work: on one hand, an extensive literature on answering questions by mapping from strings to logical representations of meaning; on the other, a series of recent successes in deep neural models for image recognition and captioning.
</p>

<p>
主要涉及了两个领域的内容
</p>
<ol class="org-ol">
<li>将自然文本形式变换成逻辑表示</li>
<li>深度神经网络在图像识别和 'image captioning' 方面的能力</li>
</ol>

<p>
Our model has two components, trained jointly: first, a collection of neural "modules" that can be freely composed; second, a network layout predictor that assembles modules into complete deep networks tailored to each question.
</p>

<p>
根据处理过程，模型可以分为两部分:
</p>
<ol class="org-ol">
<li>许多不同类型的神经网络模块</li>
<li>一个 "network layout predictor" ，用来将 "神经网络模块" 组装成一个完整的神经网络</li>
</ol>

<p>
这两部分是一起训练(trained jointly)的。
</p>

<p>
问题来了，第一部分的模型好理解，第二部分模型的输入和输出是什么呢？输入很明确，应该就是 "逻辑表示" 的问题，这个是很好进行形式化表示的，那么输出呢？应该也是一个形式化的表示，其中可能有不同 "神经网络模块" 的名称。得到这个输出后，还必须有外部程序来真正组装起最后的网络模型。但如果说这两部分是一起被训练的话……从 "network layout" 到真正的网络模型这一步， <b>其数学表示为何</b> ?而且很重要的一点，是否可微？
</p>

<p>
训练数据的话包含三部分: (world, question, answer)，其中 (world, question) 是输入， answer 是输出。没错的吧。
</p>
</div>
</div>

<div id="outline-container-orgheadline2" class="outline-2">
<h2 id="orgheadline2">Notes for page 2</h2>
<div class="outline-text-2" id="text-orgheadline2">
<p>
2015 年 Andreas 提出了一个启发式的方法来将一个 VQA 问题解构为一串子问题，比如说，"what color is the bird" 的回答被分为两步:
</p>
<ol class="org-ol">
<li>where is the bird</li>
<li>what color is that part of the image</li>
</ol>

<p>
contributions of this paper(我就理解为是作者 2016 年这篇论文而不是 2015 年的论文咯)
</p>
<ol class="org-ol">
<li><p>
an extension and generalization of this mechanism to enable fully differentiable reasoning about more structured semantic representations
</p>

<p>
这是在说本文的方法对 2015 年的方法所做的扩充，使得模型能够在更加结构化的语义表示上进行 <b>完全可微</b> 的推理
</p>

<p>
你咋不上天呢？
</p>

<p>
"by representing every entity in the universe of discourse as a feature vector, we can obtain a distribution over entities that corresponds roughly to a logical set-valued denotation"
</p>

<p>
将 world 中的 entity 表示成特征向量，可以得到 "a distribution over entities that corresponds roughly to a logical set-valued denotation"，这其中的 "a distribution over entities" 基本上就是废话，和前文是以个意思，但 "corresponds roughly to a logical set-valued denotation" 何解？ "correspond roughly to" 的意思为 "大致相当于" ，所以关键在后面那个 "logical set-valued denotation" ，set-valued 翻译为 "集值的"，那么就是 "逻辑集值表示" 咯，这是什么鬼意思……
</p>

<p>
"Having obtained such a distribution, existing neural approaches use it to immediately compute a weighted average of image feature and project back into a labeling decision"
</p>

<p>
依然没懂。不过后面倒是看明白了，大意是在描述处理的过程，第一步是将 world 中的 entity 表示成向量，然后再用 "existing neural approaches" 来得到输出，并且强调针对不同的情况应该有不同的 "neural module"，这里只说了两种：
</p>
<ul class="org-ul">
<li>combining them(by analogy to conjunction and disjunction)</li>
<li>inspecting them directly(by analogy to quantification)</li>
</ul>
<p>
总之, "Unlike their formal conterparts, they are differentiable end-to-end" ，这应该就是主要要表达的东西了。
</p></li>

<li><p>
a model for learning to assemble such modules compositionally
</p>

<p>
"Isolated modules are of limited use, they must be composed into larger structures"
</p>

<p>
"Our goal it to automatically induce variable-free, tree-structured computation descriptors." 这句话是说，为了达成上一句话所表示的目的(将 modules 组装起来)，需要引进一个 "variable-free, tree-structured" 的计算表示，然后引进了形式语言学(formal semantics) 中的功能符号。
</p>

<p>
比如说，将 "What cities are in Georgia" 表示成
</p>
<pre class="example">
(and
    find[city]
    (related[in] lookup[Georgia])
)
</pre>

<p>
而在本文中，作者使用一个称为 "dynamic neural module network" 的模型来做这个事情
</p></li>
</ol>
</div>
</div>

<div id="outline-container-orgheadline3" class="outline-2">
<h2 id="orgheadline3">Notes for page 3</h2>
<div class="outline-text-2" id="text-orgheadline3">
<p>
在文本被映射到逻辑表示后，基于数据库的 QA 的相关工作有不少.
</p>

<ol class="org-ol">
<li>"supervision may be proveded either by annotated logical forms or from (world, question, answer) triple alone"</li>
<li><p>
"in general the set of primitive functions from which these logical forms can be assembled is fixed"
</p>

<p>
提炼一下主干哈: the set of functions is fixed. 这是在说啊，其逻辑形式可以被组装起来的功能，只有那么几个而已，也就是说，可被模块化的功能，种类有限，只能处理一小部分情况。
</p>

<p>
然而嘛，这当然不是问题了，"one recent line of work focuses on inducing new predicates functions automatically, either from perceptual features or the underlying schema." 看，还是有别人在做工作缓解了这个问题的嘛
</p>

<p>
并且，作者表示 "The model we describe in this paper has a unified framework for handling both the perceptual and schema cases, and differs from existing work primarily in learning a differentiable execution model with continuous evaluation results"
</p>
<ul class="org-ul">
<li>我们的模型是一个统一的框架，既能处理 "感知输入"， 也能处理 "模式输入"(所以这两者有什么区别)</li>
<li>我们的模型是可微的，结果是连续的(而非离散的？)</li>
</ul></li>
</ol>


<p>
神经网络模型在 QA 上的应用也是目前令人感兴趣的话题之一:
</p>
<ul class="org-ul">
<li>Iyyer(2014), 将 QA 看作多类别分类问题</li>
<li>Bordes(2014), "attempt to embed questions and answers in a shared vector space"</li>
<li>Hermann(2015), 使用 attention 机制来从 "documents sources" 中挑选词汇(组成答案？)</li>
<li>Yin(2015), "learns a query execution model for database tables without any"</li>
<li>Grefenstette(2013)</li>
<li>Krishnamurthy and Mitchell(2013)</li>
</ul>


<p>
当然以上方法的问题是，需要答案能够直接能够搜索得到(require that answers can be retrieved directly based on surafce linguistic features, without any intermediate computation)
</p>

<p>
作者接着提到，自己的工作是在 CNN 在 CV 上的应用的基础上做的。
</p>

<p>
VQA:
</p>
<ul class="org-ul">
<li>Ren(2015), Malinowski(2015), 使用 RNN 来得到图像和问题的 "deep representations"</li>
<li>Yang(2015), Xu and Saenko(2015)，使用 question 来计算图像上的 attention</li>
<li>Zhou(2015), 简单的分类模型</li>
<li>Noh(2015), dynamic parameter prediction</li>
</ul>


<p>
"All of these models assume that a fixed computation can be performed on the image and question to compute the answer, rather than adapting the structure of computation to the question."
</p>

<p>
类似的工作:
</p>
<ul class="org-ul">
<li>Andreas(2015),</li>
<li>Bottou(2014), Universal parser</li>
<li>Socher(2013), recursive neural networks</li>
</ul>


<p>
不过这些工作本身还是有限制，不像本文的方法一样: "succeeds in simultaneously learning both the parameters for and struces of instance-specific neural networks"
</p>
</div>
</div>

<div id="outline-container-orgheadline4" class="outline-2">
<h2 id="orgheadline4">Notes for page 4</h2>
<div class="outline-text-2" id="text-orgheadline4">
<p>
some modules operate directly on the input representation, while others also also depend on input from specific earlier modules.
</p>

<p>
比如说， describe 这样一个 module，除了需要 world representation 作为输入外，还需要 question 中的部分信息。
</p>
</div>
</div>


<div id="outline-container-orgheadline5" class="outline-2">
<h2 id="orgheadline5">Notes for page 5</h2>
<div class="outline-text-2" id="text-orgheadline5">
</div>
</div>
